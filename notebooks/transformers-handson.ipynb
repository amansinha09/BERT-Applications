{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, CamembertTokenizer, CamembertModel, FlaubertTokenizer, FlaubertModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get word Embeddings from BERT Transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/amansinha/venv/global_env/lib/python3.8/site-packages (0.1.95)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context= ['Chez', 'Abdes', 'Ouaddou', ',', 'c’', 'est', 'tout', 'le', 'contraire', ':', 'la', 'trêve', 'estivale', '-creusé', 'a', 'les', 'joues', ',', 'fait', 'ressortir', 'les', 'pommettes', 'et', 'allongé', 'encore', 'le', 'visage', 'et', 'le', 'corps', 'de', 'ce', 'joueur', 'à', 'la', 'silhouette', 'déjà', 'filiforme', '.'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creusé</w>'] ['Chez</w>', 'Ab', 'des</w>', 'Ou', 'ad', 'dou</w>', ',</w>', 'c</w>', \"'</w>\", 'est</w>', 'tout</w>', 'le</w>', 'contraire</w>', ':</w>', 'la</w>', 'trêve</w>', 'estivale</w>', '-', 'creusé</w>', 'a</w>', 'les</w>', 'joues</w>', ',</w>', 'fait</w>', 'ressortir</w>', 'les</w>', 'pomm', 'ettes</w>', 'et</w>', 'allongé</w>', 'encore</w>', 'le</w>', 'visage</w>', 'et</w>', 'le</w>', 'corps</w>', 'de</w>', 'ce</w>', 'joueur</w>', 'à</w>', 'la</w>', 'silhouette</w>', 'déjà</w>', 'fili', 'forme</w>', '.</w>']\n"
     ]
    }
   ],
   "source": [
    "''' Initiate the bert (any transformer LM) model '''\n",
    "## flauBERT\n",
    "tokenizer = FlaubertTokenizer.from_pretrained('flaubert/flaubert_base_cased')\n",
    "model = FlaubertModel.from_pretrained('flaubert/flaubert_base_cased')\n",
    "print(tokenizer.tokenize('creusé'), tokenizer.tokenize(' '.join(context)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁creusé'] ['▁Chez', '▁Abd', 'es', '▁Ou', 'ad', 'dou', '▁', ',', '▁c', '’', '▁est', '▁tout', '▁le', '▁contraire', '▁:', '▁la', '▁trêve', '▁estivale', '▁-', 'cre', 'usé', '▁a', '▁les', '▁joues', '▁', ',', '▁fait', '▁ressortir', '▁les', '▁pomme', 'ttes', '▁et', '▁allongé', '▁encore', '▁le', '▁visage', '▁et', '▁le', '▁corps', '▁de', '▁ce', '▁joueur', '▁à', '▁la', '▁silhouette', '▁déjà', '▁fil', 'i', 'forme', '▁', '.']\n"
     ]
    }
   ],
   "source": [
    "''' Initiate the bert (any transformer LM) model '''\n",
    "## camemBERT\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "model = CamembertModel.from_pretrained('camembert-base')\n",
    "print(tokenizer.tokenize('creusé'), tokenizer.tokenize(' '.join(context)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creu', '##sé'] ['Chez', 'Abd', '##es', 'Ou', '##ad', '##dou', ',', 'c', '[UNK]', 'est', 'tout', 'le', 'contraire', ':', 'la', 'tr', '##ê', '##ve', 'esti', '##vale', '-', 'creu', '##sé', 'a', 'les', 'joue', '##s', ',', 'fait', 'res', '##sort', '##ir', 'les', 'po', '##mmet', '##tes', 'et', 'allo', '##ngé', 'encore', 'le', 'visage', 'et', 'le', 'corps', 'de', 'ce', 'joueur', 'à', 'la', 'sil', '##hou', '##ette', 'déjà', 'fil', '##if', '##orme', '.']\n"
     ]
    }
   ],
   "source": [
    "''' Initiate the bert (any transformer LM) model '''\n",
    "## BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "print(tokenizer.tokenize('creusé'), tokenizer.tokenize(' '.join(context)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'my', 'dog', 'is', 'cute']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Hello, my dog is cute\"\n",
    "\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'my', 'dog', 'is', 'cute']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)\n",
    "\n",
    "tokenizer.tokenize(\"Hello, my dog is cute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 7592, 1010, 2026, 3899, 2003, 10140, 102],\n",
       " tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello, my dog is cute\"), input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 3899, 102]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"dog\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "''' Note: 101 , 102 : are sentence start and sentence end keys '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embeddings\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'my', 'dog', 'is', 'cute']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_model = DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "distilbert_tokenizer.tokenize(\"Hello, my dog is cute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta_tokenizer(\"Hello, my dog is cute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with more classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>transworld systems inc. \\nis trying to collect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRANSWORLD SYSTEMS INC</td>\n",
       "      <td>FL</td>\n",
       "      <td>335XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3384392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>PA</td>\n",
       "      <td>15206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Communication tactics</td>\n",
       "      <td>Frequent or repeated calls</td>\n",
       "      <td>Over the past 2 weeks, I have been receiving e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diversified Consultants, Inc.</td>\n",
       "      <td>NC</td>\n",
       "      <td>275XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3433198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>NY</td>\n",
       "      <td>140XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>In progress</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4204028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>Money transfer, virtual currency, or money ser...</td>\n",
       "      <td>Mobile or digital wallet</td>\n",
       "      <td>Managing, opening, or closing your mobile wall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paypal Holdings, Inc</td>\n",
       "      <td>OR</td>\n",
       "      <td>97404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4179550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received                                            Product  \\\n",
       "0    2019-09-24                                    Debt collection   \n",
       "1    2019-09-19  Credit reporting, credit repair services, or o...   \n",
       "2    2019-11-08                                    Debt collection   \n",
       "3    2021-03-11  Credit reporting, credit repair services, or o...   \n",
       "4    2021-03-03  Money transfer, virtual currency, or money ser...   \n",
       "\n",
       "                Sub-product  \\\n",
       "0             I do not know   \n",
       "1          Credit reporting   \n",
       "2             I do not know   \n",
       "3          Credit reporting   \n",
       "4  Mobile or digital wallet   \n",
       "\n",
       "                                               Issue  \\\n",
       "0                  Attempts to collect debt not owed   \n",
       "1               Incorrect information on your report   \n",
       "2                              Communication tactics   \n",
       "3               Incorrect information on your report   \n",
       "4  Managing, opening, or closing your mobile wall...   \n",
       "\n",
       "                             Sub-issue  \\\n",
       "0                    Debt is not yours   \n",
       "1  Information belongs to someone else   \n",
       "2           Frequent or repeated calls   \n",
       "3  Information belongs to someone else   \n",
       "4                                  NaN   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0  transworld systems inc. \\nis trying to collect...   \n",
       "1                                                NaN   \n",
       "2  Over the past 2 weeks, I have been receiving e...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0                                                NaN   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                               Company State ZIP code Tags  \\\n",
       "0               TRANSWORLD SYSTEMS INC    FL    335XX  NaN   \n",
       "1  Experian Information Solutions Inc.    PA    15206  NaN   \n",
       "2        Diversified Consultants, Inc.    NC    275XX  NaN   \n",
       "3  Experian Information Solutions Inc.    NY    140XX  NaN   \n",
       "4                 Paypal Holdings, Inc    OR    97404  NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0           Consent provided           Web           2019-09-24   \n",
       "1       Consent not provided           Web           2019-09-20   \n",
       "2           Consent provided           Web           2019-11-08   \n",
       "3                        NaN           Web           2021-03-11   \n",
       "4                        NaN           Web           2021-03-03   \n",
       "\n",
       "      Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0          Closed with explanation              Yes                NaN   \n",
       "1  Closed with non-monetary relief              Yes                NaN   \n",
       "2          Closed with explanation              Yes                NaN   \n",
       "3                      In progress              Yes                NaN   \n",
       "4  Closed with non-monetary relief              Yes                NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3384392  \n",
       "1       3379500  \n",
       "2       3433198  \n",
       "3       4204028  \n",
       "4       4179550  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/amansinha/Downloads/data/COMPLAINTS/complaints.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>transworld systems inc. \\nis trying to collect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRANSWORLD SYSTEMS INC</td>\n",
       "      <td>FL</td>\n",
       "      <td>335XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3384392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>PA</td>\n",
       "      <td>15206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3379500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received                                            Product  \\\n",
       "0    2019-09-24                                    Debt collection   \n",
       "1    2019-09-19  Credit reporting, credit repair services, or o...   \n",
       "\n",
       "        Sub-product                                 Issue  \\\n",
       "0     I do not know     Attempts to collect debt not owed   \n",
       "1  Credit reporting  Incorrect information on your report   \n",
       "\n",
       "                             Sub-issue  \\\n",
       "0                    Debt is not yours   \n",
       "1  Information belongs to someone else   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0  transworld systems inc. \\nis trying to collect...   \n",
       "1                                                NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0                                                NaN   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "\n",
       "                               Company State ZIP code Tags  \\\n",
       "0               TRANSWORLD SYSTEMS INC    FL    335XX  NaN   \n",
       "1  Experian Information Solutions Inc.    PA    15206  NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0           Consent provided           Web           2019-09-24   \n",
       "1       Consent not provided           Web           2019-09-20   \n",
       "\n",
       "      Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0          Closed with explanation              Yes                NaN   \n",
       "1  Closed with non-monetary relief              Yes                NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3384392  \n",
       "1       3379500  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683024, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data[['Product', 'Consumer complaint narrative']].copy()\n",
    "df = data_final.dropna(subset=['Consumer complaint narrative'])\n",
    "\n",
    "df.columns = ['Products', 'consumer_complaint']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = df[:1000].copy()\n",
    "data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nclasses = len(list(data_final.Products.unique()))\n",
    "nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = {c:i for i, c in enumerate(list(data_final.Products.unique()))}\n",
    "data_final['labels'] = [my_classes[l] for l in data_final.Products]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     473\n",
       "0     196\n",
       "3      97\n",
       "6      80\n",
       "7      53\n",
       "5      28\n",
       "4      26\n",
       "9      21\n",
       "2      20\n",
       "10      3\n",
       "8       2\n",
       "11      1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN= 512\n",
    "TRAIN_BS = 8\n",
    "VALID_BS = 8\n",
    "EPOCHS = 1\n",
    "LR =  1e-05\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CompanyData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        complaint = str(self.data.consumer_complaint[index])\n",
    "        complaint= \" \".join(complaint.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "        complaint, \n",
    "        None,\n",
    "        add_special_tokens = True,\n",
    "        max_length=self.max_len,\n",
    "        padding = 'max_length',\n",
    "        return_token_type_ids = True,\n",
    "        truncation=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        \n",
    "        return { 'ids': torch.tensor(ids, dtype=torch.long),\n",
    "               'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.data.labels[index], dtype=torch.long)\n",
    "                \n",
    "               }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1000, 3)\n",
      "TRAIN Dataset: (800, 3)\n",
      "TEST Dataset: (200, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data_final.sample(frac= train_size, random_state=20)\n",
    "test_dataset = data_final.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data_final.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = CompanyData(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CompanyData(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BS,\n",
    "               'shuffle':True,\n",
    "               'num_workers': 2}\n",
    "test_params = {'batch_size': VALID_BS,\n",
    "              'shuffle': False,\n",
    "              'num_workers': 2}\n",
    "\n",
    "trainloader = DataLoader(training_set, **train_params)\n",
    "testloader = DataLoader(testing_set, **test_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self, nclasses):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, nclasses)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistillBERTClass(nclasses)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_acc(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/textclassify_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    \n",
    "    model.train()\n",
    "    for _, data in tqdm(enumerate(trainloader, 0)):\n",
    "        ids = data['ids'].to(device, dtype=torch.long)\n",
    "        mask = data['mask'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.long)\n",
    "        \n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calculate_acc(big_idx, targets)\n",
    "        \n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if _ % 50 == 0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            acc_step = (n_correct*100)/nb_tr_examples\n",
    "            print(f'Training Loss per 50 steps: {loss_step}, Training Accuracy: {acc_step}')\n",
    "            writer.add_scalar('training_loss', loss_step, epoch*len(trainloader) +_)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Total Accuracy Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_acc = (n_correct*100)/nb_tr_examples\n",
    "    print(f'Training Loss Epoch: {epoch_loss}, Training Accuracy Epoch: {epoch_acc}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "def valid(model, testloader):\n",
    "    model.eval()\n",
    "    n_correct =0; n_wrong =0; total=0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testloader, 0):\n",
    "            ids = data['ids'].to(device, dtype=torch.long)\n",
    "            mask = data['mask'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.long)\n",
    "            \n",
    "            outputs = model(ids, mask)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calculate_acc(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples += targets.size(0)\n",
    "            \n",
    "            if _ % 100 == 0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                acc_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f'Validation Loss per 100 steps: {loss_step}, Validation Accuracy per: {acc_step}')   \n",
    "        \n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_acc = (n_correct*100)/nb_tr_examples\n",
    "    print(f'Validation Loss Epoch: {epoch_loss}, Validation Accuracy Epoch: {epoch_acc}')\n",
    "    \n",
    "    return epoch_acc\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 50 steps: 2.4796786308288574, Training Accuracy: 12.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [05:56,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 50 steps: 2.0047876016766417, Training Accuracy: 44.36274509803921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [12:49,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy Epoch 0: 45.375\n",
      "Training Loss Epoch: 1.8629813945293427, Training Accuracy Epoch: 45.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = valid(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb\n",
    "* https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb#scrollTo=E0Cr8FlFT-OL\n",
    "* https://www.kaggle.com/selener/multi-class-text-classification-tfidf\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database/resource/8a4d00ff-81c1-460d-99b9-1315a2b45947\n",
    "* https://mccormickml.com/2019/07/22/BERT-fine-tuning/#introduction\n",
    "* https://github.com/huggingface/transformers/issues/1950\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
